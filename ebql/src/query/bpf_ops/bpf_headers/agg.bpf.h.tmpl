#pragma once

/**
 * Implement aggregations in eBPF for the query {{query_name}}.
 */

#include "common.bpf.h"
#include "{{query_name}}.bpf.h"

// Depending on group by key, can reduce number of max entries (e.g. for cpu, only need # cpus)
#define AGG_MAX_ENTRIES ({{gb_max_entries}})

// Since BPF doesn't allow FP, scale values by AVG_SCALE (4 -> +4 sigfigs)
#define AVG_SCALE ({{avg_scale}})

typedef struct {
  {{#each group_bys}}
  {{field_type}} {{field_name}};
  {{/each}}
} group_by_{{query_name}}_t;

// Avg counter for individual item.
typedef struct {
  // Note: the averaged value doesn't have to be u64, but do this to prevent
  // overflows.
  u64 val;
  u64 count;
} avg_t;

// Use val for min/max/count
typedef struct {
  u64 val;
} agg_t;

// Simple aggregations
static __always_inline void max(agg_t *agg, u64 val) {
  if (val > agg->val) agg->val = val;
}
static __always_inline void min(agg_t *agg, u64 val) {
  if (val < agg->val) agg->val = val;
}
static __always_inline void count(agg_t *agg, u64 val) { agg->val += 1; }
static __always_inline void sum(agg_t *agg, u64 val) { agg->val += val; }
static __always_inline void avg(avg_t *agg, u64 val) {
  agg->val = (agg->val * agg->count + AVG_SCALE * val) / (agg->count + 1);
  agg->count += 1;
}

{{#each aggs}}
struct {
  __uint(type, BPF_MAP_TYPE_HASH);
  __type(key, group_by_simple_1_t);
{{#if is_avg}}
  __type(value, avg_t);
{{else}}
  __type(value, agg_t);
{{/if}}
  __uint(max_entries, AGG_MAX_ENTRIES);
  __uint(map_flags, BPF_F_NO_PREALLOC);
} {{agg}}_{{field_name}}_{{query_name}} SEC(".maps");
{{/each}}

{{#each aggs}}
static __always_inline s32 insert_{{agg}}_{{field_name}}_{{query_name}}(group_by_{{query_name}}_t key, u64 val) {
  s32 ret;
  {{#if is_avg}}
  avg_t *agg = (avg_t *)bpf_map_lookup_elem(&{{agg}}_{{field_name}}_{{query_name}}, &key);
  {{else}}
  agg_t *agg = (agg_t *)bpf_map_lookup_elem(&{{agg}}_{{field_name}}_{{query_name}}, &key);
  {{/if}}
  if (!agg) {
    {{#if is_avg}}
    avg_t init = {AVG_SCALE * val, 1};
    {{else}}
    agg_t init = {val};
    {{/if}}
    ret = bpf_map_update_elem(&{{agg}}_{{field_name}}_{{query_name}}, &key, &init, BPF_NOEXIST);
  } else {
    {{agg}}(agg, val);
  }
  if (ret != 0) {
    ERROR("failed to insert into {{agg}} map: %d", ret);
  }
  return ret;
}

typedef struct {
  simple_1_t *buf;
  u64 buf_sz;
  u64 count;
} {{agg}}_{{field_name}}_{{query_name}}_ctx_t;

static __always_inline s64 __get_{{agg}}_{{field_name}}_{{query_name}}_callback(struct bpf_map *map,
                                                           group_by_{{query_name}}_t *key,
                                                           {{#if is_avg}}
                                                           avg_t *agg,
                                                           {{else}}
                                                           agg_t *agg,
                                                           {{/if}}
                                                           {{agg}}_{{field_name}}_{{query_name}}_ctx_t *ctx) {
  // Set agg value
  if (!ctx || !ctx->buf) {
    ERROR("Passed null context/context buffer in");
    return 1;
  }
  if (ctx->count >= ctx->buf_sz) {
    WARN("Number of aggregation results exceeds buf size; stopping...");
    return 1;
  }
  {{#each ../group_bys}}
  ctx->buf[ctx->count].{{field_name}} = key->{{field_name}};
  {{/each}}
  ctx->buf[ctx->count].{{agg}}_{{field_name}} = agg->val;
  {{#if is_avg}}
  // Scale back to normal value
  ctx->buf[ctx->count].{{agg}}_{{field_name}} /= AVG_SCALE;
  ctx->buf[ctx->count].{{agg}}_{{field_name}}_count = agg->count;
  {{/if}}
}

static __always_inline u64 get_{{agg}}_{{field_name}}_{{query_name}}({{query_name}}_t *buf, u64 buf_sz) {
  {{agg}}_{{field_name}}_{{query_name}}_ctx_t ctx = {.buf = buf, .buf_sz = buf_sz, .count = 0};
  bpf_for_each_map_elem(&{{agg}}_{{field_name}}_{{query_name}}, __get_{{agg}}_{{field_name}}_{{query_name}}_callback, &ctx, 0);
}

static __always_inline u64 __count_{{agg}}_{{field_name}}_{{query_name}}_callback(struct bpf_map *map,
                                                             group_by_simple_1_t *key,
                                                             void *val,
                                                             u64 *count) {
  *count += 1;
  return 0;
}

static __always_inline u64 count_{{agg}}_{{field_name}}_{{query_name}}() {
  u64 count = 0;
  bpf_for_each_map_elem(&{{agg}}_{{field_name}}_{{query_name}}, __count_{{agg}}_{{field_name}}_{{query_name}}_callback, &count, 0);
}

static __always_inline u64 __tumble_{{agg}}_{{field_name}}_{{query_name}}_callback(struct bpf_map *map,
                                                             group_by_simple_1_t *key,
                                                             {{#if is_avg}}
                                                             avg_t *agg,
                                                             {{else}}
                                                             agg_t *agg,
                                                             {{/if}}
                                                             void *ctx) {
  agg->val = 0;
  {{#if is_avg}}
  agg->count = 0;
  {{/if}}
}

static __always_inline u64 tumble_{{agg}}_{{field_name}}_{{query_name}}() {
  bpf_for_each_map_elem(&{{agg}}_{{field_name}}_{{query_name}}, __tumble_{{agg}}_{{field_name}}_{{query_name}}_callback, NULL, 0);
}

{{/each}}